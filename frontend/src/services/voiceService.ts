// è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆæœåŠ¡ - æ”¯æŒå¤šç§TTSå¼•æ“
export class VoiceService {
  private recognition: any = null
  private synthesis: SpeechSynthesis
  private isRecognitionSupported: boolean
  private isSynthesisSupported: boolean
  private currentAudio: HTMLAudioElement | null = null
  private isPlaying: boolean = false

  // TTSå¼•æ“é…ç½®
  private ttsConfig = {
    // ä¼˜å…ˆä½¿ç”¨Edge-TTS (æ›´è‡ªç„¶çš„è¯­éŸ³)
    useEdgeTTS: true,
    // å¤‡ç”¨ä½¿ç”¨æµè§ˆå™¨å†…ç½®TTS
    fallbackToWebAPI: true,
    // è§’è‰²ä¸“å±è¯­éŸ³é…ç½®
    characterVoices: {
      'harry-potter': {
        edgeVoice: 'zh-CN-YunyeNeural',     
        webVoice: 'Microsoft Kangkang - Chinese (Simplified, PRC)', // ç”·å£°
        rate: 2.3,
        pitch: 0.9
      },
      'socrates': {
        edgeVoice: 'zh-CN-YunjianNeural',    // æˆç†Ÿç”·æ€§ï¼Œæ²‰ç¨³
        webVoice: 'Microsoft Kangkang - Chinese (Simplified, PRC)',
        rate: 2.1,
        pitch: 0.9
      },
      'sherlock': {
        edgeVoice: 'zh-CN-YunxiNeural',      // ç†æ€§ç”·æ€§ï¼Œæ¸…æ™°
        webVoice: 'Microsoft Kangkang - Chinese (Simplified, PRC)',
        rate: 2.1,
        pitch: 0.95
      },
      'einstein': {
        edgeVoice: 'zh-CN-YunyangNeural',    // æ™ºæ…§ç”·æ€§ï¼Œæ¸©å’Œ
        webVoice: 'Microsoft Kangkang - Chinese (Simplified, PRC)',
        rate: 2.1,
        pitch: 1.0
      },
      'shakespeare': {
        edgeVoice: 'zh-CN-YunjianNeural',     // ä¼˜é›…å¥³æ€§ï¼Œè¯—æ„
        webVoice: 'Microsoft Huihui - Chinese (Simplified, PRC)',
        rate: 2.1,
        pitch: 1.05
      },
      'confucius': {
        edgeVoice: 'zh-CN-YunjianNeural',    // é•¿è€…ç”·æ€§ï¼Œåº„é‡
        webVoice: 'Microsoft Kangkang - Chinese (Simplified, PRC)',
        rate: 2.0,
        pitch: 0.85
      }
    }
  }

  constructor() {
    // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
    this.isRecognitionSupported = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window
    if (this.isRecognitionSupported) {
      this.recognition = new ((window as any).webkitSpeechRecognition || (window as any).SpeechRecognition)()
      this.setupRecognition()
    }

    // åˆå§‹åŒ–è¯­éŸ³åˆæˆ
    this.synthesis = window.speechSynthesis
    this.isSynthesisSupported = 'speechSynthesis' in window
  }

  private setupRecognition() {
    if (!this.recognition) return

    this.recognition.continuous = false
    this.recognition.interimResults = false
    this.recognition.lang = 'zh-CN'
    this.recognition.maxAlternatives = 1
  }

  // å¼€å§‹è¯­éŸ³è¯†åˆ«
  async startRecognition(): Promise<string> {
    return new Promise((resolve, reject) => {
      if (!this.isRecognitionSupported || !this.recognition) {
        reject(new Error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«'))
        return
      }

      this.recognition.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript
        resolve(transcript)
      }

      this.recognition.onerror = (event: any) => {
        reject(new Error(`è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`))
      }

      this.recognition.onend = () => {
        // è¯†åˆ«ç»“æŸï¼Œå¦‚æœæ²¡æœ‰ç»“æœåˆ™è§¦å‘é”™è¯¯
      }

      try {
        this.recognition.start()
      } catch (error) {
        reject(error)
      }
    })
  }

  // åœæ­¢è¯­éŸ³è¯†åˆ«
  stopRecognition() {
    if (this.recognition) {
      this.recognition.stop()
    }
  }

  // å¢å¼ºçš„è¯­éŸ³åˆæˆ - æ”¯æŒå¤šç§TTSå¼•æ“
  async speak(text: string, characterId: string = '', options: {
    rate?: number
    pitch?: number
    volume?: number
    voice?: string
    lang?: string
  } = {}): Promise<void> {
    console.log('ğŸ”Š å¼€å§‹è¯­éŸ³åˆæˆ:', { text: text.substring(0, 50) + '...', characterId, isSynthesisSupported: this.isSynthesisSupported })
    
    try {
      // åœæ­¢å½“å‰æ’­æ”¾
      this.stopSpeaking()

      // è·å–è§’è‰²è¯­éŸ³é…ç½®
      const voiceConfig = this.getCharacterVoiceSettings(characterId)
      console.log('ğŸ­ è§’è‰²è¯­éŸ³é…ç½®:', voiceConfig)
      
      // ä¼˜å…ˆå°è¯•ä½¿ç”¨Edge-TTS
      if (this.ttsConfig.useEdgeTTS) {
        try {
          await this.speakWithEdgeTTS(text, characterId, voiceConfig)
          return
        } catch (error) {
          console.log('Edge-TTSä¸å¯ç”¨ï¼Œä½¿ç”¨æµè§ˆå™¨å†…ç½®TTS:', error)
        }
      }

      // å¤‡ç”¨ï¼šä½¿ç”¨æµè§ˆå™¨å†…ç½®TTS
      if (this.ttsConfig.fallbackToWebAPI) {
        console.log('ğŸ“¢ åˆ‡æ¢åˆ°æµè§ˆå™¨å†…ç½®TTS')
        try {
          await this.speakWithWebAPI(text, voiceConfig, options)
          console.log('âœ… æµè§ˆå™¨TTSæ‰§è¡ŒæˆåŠŸ')
        } catch (webApiError) {
          console.error('âŒ æµè§ˆå™¨TTSä¹Ÿå¤±è´¥äº†:', webApiError)
          throw webApiError
        }
      } else {
        console.error('âŒ æ‰€æœ‰TTSå¼•æ“éƒ½ä¸å¯ç”¨')
        throw new Error('æ²¡æœ‰å¯ç”¨çš„TTSå¼•æ“')
      }
    } catch (error) {
      console.error('è¯­éŸ³åˆæˆå¤±è´¥:', error)
      throw error
    }
  }

  // Edge-TTSè¯­éŸ³åˆæˆï¼ˆæ›´è‡ªç„¶ï¼‰- æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿå®ç°
  private async speakWithEdgeTTS(_text: string, _characterId: string, _voiceConfig: any): Promise<void> {
    // æš‚æ—¶æŠ›å‡ºé”™è¯¯ï¼Œè®©ç³»ç»Ÿä½¿ç”¨æµè§ˆå™¨TTS
    // æœªæ¥å¯ä»¥é›†æˆçœŸå®çš„Edge-TTSæœåŠ¡
    throw new Error('Edge-TTSæœåŠ¡æš‚æœªéƒ¨ç½²ï¼Œä½¿ç”¨æµè§ˆå™¨å†…ç½®TTS')
    
    /* 
    // çœŸå®çš„Edge-TTSå®ç°ï¼ˆéœ€è¦åç«¯æ”¯æŒï¼‰
    return new Promise(async (resolve, reject) => {
      try {
        const voiceName = voiceConfig.edgeVoice || 'zh-CN-XiaoxiaoNeural'
        const rate = `${Math.round((voiceConfig.rate || 1.0) * 100)}%`
        const pitch = `${Math.round(((voiceConfig.pitch || 1.0) - 1) * 50)}Hz`

        // æ„å»ºSSML
        const ssml = `
          <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="zh-CN">
            <voice name="${voiceName}">
              <prosody rate="${rate}" pitch="${pitch}">
                ${this.escapeXml(text)}
              </prosody>
            </voice>
          </speak>
        `

        // ä½¿ç”¨Edge-TTS API (é€šè¿‡ä»£ç†æœåŠ¡)
        const response = await fetch('/api/tts/edge', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            ssml: ssml,
            voice: voiceName,
            format: 'audio-24khz-48kbitrate-mono-mp3'
          })
        })

        if (!response.ok) {
          throw new Error(`Edge-TTS API error: ${response.status}`)
        }

        const audioBlob = await response.blob()
        const audioUrl = URL.createObjectURL(audioBlob)
        
        this.currentAudio = new Audio(audioUrl)
        this.currentAudio.onended = () => {
          this.isPlaying = false
          URL.revokeObjectURL(audioUrl)
          resolve()
        }
        this.currentAudio.onerror = () => {
          this.isPlaying = false
          URL.revokeObjectURL(audioUrl)
          reject(new Error('éŸ³é¢‘æ’­æ”¾å¤±è´¥'))
        }

        this.isPlaying = true
        await this.currentAudio.play()
        
      } catch (error) {
        reject(error)
      }
    })
    */
  }

  // æµè§ˆå™¨å†…ç½®TTSï¼ˆå¤‡ç”¨ï¼‰
  private async speakWithWebAPI(text: string, voiceConfig: any, _options: any): Promise<void> {
    console.log('ğŸŒ å¼€å§‹æµè§ˆå™¨TTSåˆæˆï¼Œæ–‡æœ¬é•¿åº¦:', text.length)
    
    return new Promise((resolve, reject) => {
      if (!this.isSynthesisSupported) {
        console.error('âŒ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ')
        reject(new Error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ'))
        return
      }

      // ç®€åŒ–å®ç°ï¼šç›´æ¥ä½¿ç”¨speechSynthesisï¼Œä¸ç­‰å¾…voicesåŠ è½½
      console.log('ğŸµ åˆ›å»ºè¯­éŸ³åˆæˆä»»åŠ¡')
      
      const utterance = new SpeechSynthesisUtterance(text)
      
      // è®¾ç½®åŸºæœ¬å‚æ•°
      utterance.rate = voiceConfig.rate || 0.9
      utterance.pitch = voiceConfig.pitch || 1.0
      utterance.volume = 0.9
      utterance.lang = 'zh-CN'
      
      console.log('ï¿½ è¯­éŸ³å‚æ•°:', { 
        rate: utterance.rate, 
        pitch: utterance.pitch, 
        volume: utterance.volume,
        lang: utterance.lang 
      })

      // å°è¯•é€‰æ‹©ä¸­æ–‡è¯­éŸ³
      const voices = this.synthesis.getVoices()
      console.log('ğŸ¤ æ€»è¯­éŸ³æ•°é‡:', voices.length)
      
      if (voices.length > 0) {
        const chineseVoices = voices.filter(voice => 
          voice.lang.includes('zh') || 
          voice.name.includes('Chinese') ||
          voice.name.includes('ä¸­æ–‡')
        )
        
        console.log('ğŸ‡¨ğŸ‡³ ä¸­æ–‡è¯­éŸ³æ•°é‡:', chineseVoices.length)
        console.log('ğŸµ ä¸­æ–‡è¯­éŸ³åˆ—è¡¨:', chineseVoices.map(v => `${v.name} (${v.lang})`))
        
        if (chineseVoices.length > 0 && chineseVoices[0]) {
          utterance.voice = chineseVoices[0]
          console.log('âœ… é€‰æ‹©è¯­éŸ³:', chineseVoices[0].name)
        }
      }

      // è®¾ç½®äº‹ä»¶ç›‘å¬
      utterance.onstart = () => {
        console.log('â–¶ï¸ è¯­éŸ³å¼€å§‹æ’­æ”¾')
        this.isPlaying = true
      }

      utterance.onend = () => {
        console.log('â¹ï¸ è¯­éŸ³æ’­æ”¾å®Œæˆ')
        this.isPlaying = false
        resolve()
      }

      utterance.onerror = (event) => {
        // console.error('âŒ è¯­éŸ³æ’­æ”¾é”™è¯¯:', event.error, event)
        this.isPlaying = false
        reject(new Error(`è¯­éŸ³åˆæˆé”™è¯¯: ${event.error}`))
      }

      utterance.onpause = () => {
        console.log('â¸ï¸ è¯­éŸ³æš‚åœ')
      }

      utterance.onresume = () => {
        console.log('â–¶ï¸ è¯­éŸ³æ¢å¤')
      }

      // å‘é€åˆ°è¯­éŸ³åˆæˆ
      console.log('ğŸ“¢ è°ƒç”¨ speechSynthesis.speak()')
      try {
        this.synthesis.speak(utterance)
        console.log('âœ… speechSynthesis.speak() è°ƒç”¨æˆåŠŸ')
      } catch (error) {
        console.error('âŒ speechSynthesis.speak() è°ƒç”¨å¤±è´¥:', error)
        reject(error)
      }
    })
  }

  // åˆ†å¥å¤„ç†æ–‡æœ¬
  private splitIntoSentences(text: string): string[] {
    // ç®€åŒ–çš„åˆ†å¥å¤„ç†ï¼ŒæŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å¥
    let sentences = text.split(/[ã€‚ï¼ï¼Ÿ]+/).filter(s => s.trim().length > 0)
    
    // å¦‚æœæ²¡æœ‰åˆ†å‡ºå¥å­ï¼ŒæŒ‰é€—å·åˆ†å¥
    if (sentences.length <= 1) {
      sentences = text.split(/[ï¼Œï¼›\n]+/).filter(s => s.trim().length > 0)
    }
    
    // å¦‚æœè¿˜æ˜¯åªæœ‰ä¸€å¥ï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡
    if (sentences.length <= 1) {
      sentences = [text]
    }
    
    console.log('ğŸ“ åˆ†å¥ç»“æœ:', sentences)
    return sentences
  }

  // é€å¥æ’­æ”¾
  private speakSentencesSequentially(
    sentences: string[], 
    voiceConfig: any, 
    options: any, 
    resolve: () => void, 
    reject: (error: Error) => void,
    index: number = 0
  ): void {
    console.log(`ğŸ¯ æ’­æ”¾ç¬¬ ${index + 1}/${sentences.length} å¥:`, sentences[index]?.substring(0, 30) + '...')
    
    if (!this.isPlaying || index >= sentences.length) {
      console.log('âœ… è¯­éŸ³æ’­æ”¾å®Œæˆ')
      this.isPlaying = false
      resolve()
      return
    }

    const sentence = sentences[index]?.trim() || ''
    if (!sentence) {
      // è·³è¿‡ç©ºå¥å­
      this.speakSentencesSequentially(sentences, voiceConfig, options, resolve, reject, index + 1)
      return
    }

    const utterance = new SpeechSynthesisUtterance(sentence)
    
    // ä¼˜åŒ–è¯­éŸ³å‚æ•°
    utterance.rate = voiceConfig.rate || 1.2
    utterance.pitch = voiceConfig.pitch || 1.0
    utterance.volume = 0.9
    utterance.lang = 'zh-CN'

    // é€‰æ‹©æœ€ä½³ä¸­æ–‡è¯­éŸ³
    const voices = this.getChineseVoices()
    console.log('ğŸ¤ å¯ç”¨ä¸­æ–‡è¯­éŸ³:', voices.map(v => v.name))
    
    if (voices.length > 0) {
      // ä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡è¯­éŸ³
      let selectedVoice = voices.find(voice => 
        voice.name.includes('Kangkang') || 
        voice.name.includes('Xiaoxiao') ||
        voice.name.includes('Yunyang')
      )
      
      if (!selectedVoice) {
        selectedVoice = voices[0]
      }
      
      console.log('ğŸµ é€‰æ‹©è¯­éŸ³:', selectedVoice?.name)
      if (selectedVoice) {
        utterance.voice = selectedVoice
      }
    }

    utterance.onstart = () => {
      console.log('â–¶ï¸ å¼€å§‹æ’­æ”¾è¯­éŸ³')
    }

    utterance.onend = () => {
      console.log('â¹ï¸ å¥å­æ’­æ”¾å®Œæˆï¼Œå‡†å¤‡ä¸‹ä¸€å¥')
      
      // æ·»åŠ çŸ­æš‚åœé¡¿åæ’­æ”¾ä¸‹ä¸€å¥
      setTimeout(() => {
        this.speakSentencesSequentially(sentences, voiceConfig, options, resolve, reject, index + 1)
      }, 200)
    }

    utterance.onerror = (event) => {
      // console.error('âŒ è¯­éŸ³æ’­æ”¾é”™è¯¯:', event.error)
      this.isPlaying = false
      reject(new Error(`è¯­éŸ³åˆæˆé”™è¯¯: ${event.error}`))
    }

    if (index === 0) {
      this.isPlaying = true
      console.log('ğŸ¬ å¼€å§‹è¯­éŸ³æ’­æ”¾åºåˆ—')
    }

    console.log('ğŸ“¢ å‘é€è¯­éŸ³åˆ°synthesis.speak')
    this.synthesis.speak(utterance)
  }

  // XMLè½¬ä¹‰
  private escapeXml(text: string): string {
    return text
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&apos;')
  }

  // åœæ­¢è¯­éŸ³æ’­æ”¾
  stopSpeaking() {
    this.isPlaying = false
    
    // åœæ­¢Edge-TTSéŸ³é¢‘
    if (this.currentAudio) {
      this.currentAudio.pause()
      this.currentAudio.currentTime = 0
      this.currentAudio = null
    }
    
    // åœæ­¢æµè§ˆå™¨å†…ç½®TTS
    if (this.synthesis) {
      this.synthesis.cancel()
    }
  }

  // æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾
  isCurrentlyPlaying(): boolean {
    return this.isPlaying
  }

  // è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨
  getVoices(): SpeechSynthesisVoice[] {
    if (!this.isSynthesisSupported) return []
    return this.synthesis.getVoices()
  }

  // è·å–ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
  getChineseVoices(): SpeechSynthesisVoice[] {
    return this.getVoices().filter(voice => 
      voice.lang.startsWith('zh') || 
      voice.name.includes('Chinese') ||
      voice.name.includes('ä¸­æ–‡') ||
      voice.name.includes('Mandarin')
    )
  }

  // æ£€æŸ¥æ”¯æŒçŠ¶æ€
  isRecognitionEnabled(): boolean {
    return this.isRecognitionSupported
  }

  isSynthesisEnabled(): boolean {
    return this.isSynthesisSupported
  }

  // è·å–é€‚åˆè§’è‰²çš„è¯­éŸ³è®¾ç½®
  getCharacterVoiceSettings(characterId: string): {
    rate: number
    pitch: number
    edgeVoice?: string
    webVoice?: string
  } {
    const characterVoices = this.ttsConfig.characterVoices as any
    return characterVoices[characterId] || {
      rate: 0.9,
      pitch: 1.0,
      edgeVoice: 'zh-CN-YunjianNeural',
      webVoice: 'Microsoft Kangkang - Chinese (Simplified, PRC)'
    }
  }

  // è®¾ç½®TTSå¼•æ“åå¥½
  setTTSPreference(useEdgeTTS: boolean, fallbackToWebAPI: boolean = true) {
    this.ttsConfig.useEdgeTTS = useEdgeTTS
    this.ttsConfig.fallbackToWebAPI = fallbackToWebAPI
  }

  // è·å–å¯ç”¨çš„Edgeè¯­éŸ³åˆ—è¡¨
  getAvailableEdgeVoices(): string[] {
    return [
      'zh-CN-YunyeNeural',     // ç”·æ€§ï¼Œæ´»æ³¼
      'zh-CN-YunjianNeural',   // ç”·æ€§ï¼Œæ²‰ç¨³
      'zh-CN-YunxiNeural',     // ç”·æ€§ï¼Œæ¸…æ™°
      'zh-CN-YunyangNeural',   // ç”·æ€§ï¼Œæ¸©å’Œ
    ]
  }
}

export const voiceService = new VoiceService()